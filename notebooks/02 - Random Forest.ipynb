{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd704b92",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Our next notebook will look at random forests.\n",
    "\n",
    "The easiest way to think of random forests is to imagine creating a whole series of decision trees, each of which might get slightly different data or some limitation in the features it can use.  Gather the outcomes of all of those trees and use them to come to some consensus.  Let's compare our decision tree classifier from the prior notebook to the random forest classifier here and see if we can get a better result than before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca08e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = ensemble.RandomForestClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d0026",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "For this demo, we will load a dataset of individuals and whether they have a high chance of long-term heart disease (output = 1) after a heart attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72625e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_attack_data = \"../data/HeartAttackData.csv\"\n",
    "df = pd.read_csv(heart_attack_data, header=0)\n",
    "\n",
    "# Review the data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2ef5d",
   "metadata": {},
   "source": [
    "These measures aren't very self-explanatory, so let's explain them here.  These are the same explanations that we saw in the CART notebook, but they're included again here for clarity.\n",
    "\n",
    "- `age` = Age of patient\n",
    "- `sex` = Sex of the patient (0 = female, 1 = male)\n",
    "- `cp` = Type of chest pain.\n",
    "  - 1 = Typical angina\n",
    "  - 2 = Atypical angina\n",
    "  - 3 = Non-anginal pain\n",
    "  - 4 = Asymptomatic\n",
    "- `trtbps` = Resting blood pressure (mm/Hg)\n",
    "- `chol` = Cholesterol level\n",
    "- `fbs` = Fasting blood sugar above 120 mg/dl\n",
    "- `restecg` = Resting ECG result\n",
    "  - 0 = Normal\n",
    "  - 1 = ST-T wave abnormality\n",
    "  - 2 = Probable or definite left ventricular hypertrophy\n",
    "- `thalachh` = Maximum heart rate achieved\n",
    "- `exng` = Exercise-induced angina (1 = yes, 0 = no)\n",
    "- `oldpeak` = Previous peak\n",
    "- `slp` = Slope\n",
    "- `caa` = Number of major vessels (0-3)\n",
    "- `thall` = Thalium Stress Test result (ranges from 0-3)\n",
    "- `output` = Diagnosis of heart disease (0 = < 50% diameter narrowing, 1 = > 50% diameter narrowing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf81282",
   "metadata": {},
   "source": [
    "## Split Labels from Features\n",
    "\n",
    "Let's now create two variables:  `y`, which is the thing we want to predict (output: `{ 0, 1 }`); and `X`, which is everything we can use to predict the specific value of `y`.\n",
    "\n",
    "With Python, splitting data out like this will not shuffle the results (something we might have to worry about if we split the data up in SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9547108",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['output']\n",
    "X = df.drop('output', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c2ce9",
   "metadata": {},
   "source": [
    "## Split into Training & Test Datasets\n",
    "\n",
    "The sklearn library has a method called `train_test_split` which breaks our data out into training and test datasets.  This allows us to train a model on one set of data and then see how it would perform on a completely different set of data.  This gives us a better idea of how our model might perform than simply using accuracy from the test dataset, as models tend to **overfit**:  they latch on the peculiarities of the training dataset.  If those peculiarities do not also exist in the broader population, then the trained model may come up with the wrong answer.  Having a separate test dataset that the trained model knows nothing about gives us a better idea of realistic behavior.  It also allows us to come up with a measure of how much overfitting the trained model does, as we can compare the training accuracy to the test accuracy; if there is a substantial difference between the two, our model is overfitting quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1740)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8603530",
   "metadata": {},
   "source": [
    "## Perform Classification\n",
    "\n",
    "We'll train the model on our training data, ignoring the test data for now.  With sklearn, this is easy:  use the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05964a",
   "metadata": {},
   "source": [
    "## How'd we do?\n",
    "\n",
    "Let's use the `accuracy_score` method in sklearn to see just how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7763f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5fd1d",
   "metadata": {},
   "source": [
    "Our accuracy score is now 83.5%, whereas for CART, it was 75.8%.  It would appear that the random forest classifier is better than the decision tree classifier when it comes to this dataset.\n",
    "\n",
    "This is fairly normal behavior--we typically see random forests beat individual decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19683c74",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "\n",
    "We stuck with most of the defaults, save for the max depth of each tree. But there are several parameters we can work with along the way. The question is, how do we decide what settings to use? We could perform ad hoc random search, tweaking parameters until we get an outcome that looks okay. That's not the only (or even the best) way to do things, however. Let's try using a technique known as randomized search.\n",
    "\n",
    "The definition of `RandomForestClassifier()` is as follows:\n",
    "\n",
    "```\n",
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)[source]\n",
    "```\n",
    "\n",
    "Things that look interesting include:\n",
    "\n",
    "* n_estimators - The number of estimators (trees) we create in the forest.\n",
    "* criterion - One of { gini, entropy, log_loss }\n",
    "* max_depth - The maximum number of levels beneath the root node\n",
    "* min_samples_split - The minimum number of samples needed to split an internal node\n",
    "* min_samples_leaf - The minimum number of samples needed in a leaf node\n",
    "* max_features - The maximum number of features to consider per split. One of { sqrt, log2 } or specify a number/percent\n",
    "* max_leaf_nodes - Grow up to this many leaf nodes in a best-first fashion\n",
    "\n",
    "Let's come up with a set of parameters that we could try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd13859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [40, 50, 75, 100, 125, 150],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b38d4",
   "metadata": {},
   "source": [
    "If you do the math on this, there are 6 * 3 * 6 * 2 * 5 = 1080 possible parameter combinations. This could take a while if we wanted to use a thorough grid search.\n",
    "\n",
    "That's why we're going to use randomized search and pick 40 parameter combinations at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb57a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "clf = RandomizedSearchCV(rf, parameters, n_iter=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684cbe6",
   "metadata": {},
   "source": [
    "Now let's run the `fit()` method, which will generate results for each set of parameters. This will take a little longer because we're training 40 separate times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d4b79",
   "metadata": {},
   "source": [
    "Once it finishes, we can determine what the best set of parameters is given our particular search criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc375f8",
   "metadata": {},
   "source": [
    "Let's see what it looks like when we fill in these values. We'll create one more classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier(max_depth=3, n_estimators=125, min_samples_leaf=3, max_features='sqrt', criterion='gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22dd43",
   "metadata": {},
   "source": [
    "Now let's fit the new model. Arguably, we don't **need** to do this because we've already done the dirty work, but one more iteration doesn't take much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e66d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e1266",
   "metadata": {},
   "source": [
    "Then, we can generate predictions and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4129f316",
   "metadata": {},
   "source": [
    "It turns out that there might be a small benefit in this particular dataset by performing randomized or grid search. We're probably not going to break 85-86%, but will get closer to the peak more frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8acc34",
   "metadata": {},
   "source": [
    "## Viewing a sample Tree\n",
    "\n",
    "As mentioned above, the random forest classifier is really just a series of decision trees.  Let's use the `graphviz` library to visualize the first of those trees.\n",
    "\n",
    "In order to run this section, you will need the `graphviz` library.  You can get it from pip or conda:\n",
    "\n",
    "`conda install python-graphviz`\n",
    "\n",
    "`pip install graphviz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "dot_data = tree.export_graphviz(clf.estimators_[20], out_file=None, feature_names=X.columns.values.tolist(), class_names=['No heart attack', 'Heart attack'], filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db519e3e",
   "metadata": {},
   "source": [
    "Leaf nodes in **blue** were cases where there was long-term heart disease, and leaf nodes in **orange** had no long-term heart disease.  Non-leaf nodes are colored based on how likely they are to indicate heart disease.\n",
    "\n",
    "As a reminder, the single decision tree from the prior notebook started with `thall <= 2.5`, so we can tell that this tree is definitely starting off differently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a00ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
