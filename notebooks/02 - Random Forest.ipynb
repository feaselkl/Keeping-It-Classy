{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Our next notebook will look at random forests.\n",
    "\n",
    "The easiest way to think of random forests is to imagine creating a whole series of decision trees, each of which might get slightly different data or some limitation in the features it can use.  Gather the outcomes of all of those trees and use them to come to some consensus.  Let's compare our decision tree classifier from the prior notebook to the random forest classifier here and see if we can get a better result than before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "For this demo, we will load a dataset of individuals and whether they have a high chance of heart attack (output = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_attack_data = \"../data/HeartAttackData.csv\"\n",
    "df = pd.read_csv(heart_attack_data, header=0)\n",
    "\n",
    "# Review the data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These measures aren't very self-explanatory, so let's explain them here.  These are the same explanations that we saw in the CART notebook, but they're included again here for clarity.\n",
    "\n",
    "- `age` = Age of patient\n",
    "- `sex` = Sex of the patient (0 = female, 1 = male)\n",
    "- `cp` = Type of chest pain.\n",
    "  - 1 = Typical angina\n",
    "  - 2 = Atypical angina\n",
    "  - 3 = Non-anginal pain\n",
    "  - 4 = Asymptomatic\n",
    "- `trtbps` = Resting blood pressure (mm/Hg)\n",
    "- `chol` = Cholesterol level\n",
    "- `fbs` = Fasting blood sugar above 120 mg/dl\n",
    "- `restecg` = Resting ECG result\n",
    "  - 0 = Normal\n",
    "  - 1 = ST-T wave abnormality\n",
    "  - 2 = Probable or definite left ventricular hypertrophy\n",
    "- `thalachh` = Maximum heart rate achieved\n",
    "- `exng` = Exercise-induced angina (1 = yes, 0 = no)\n",
    "- `oldpeak` = Previous peak\n",
    "- `slp` = Slope\n",
    "- `caa` = Number of major vessels (0-3)\n",
    "- `thall` = Thalium Stress Test result (ranges from 0-3)\n",
    "- `output` = Diagnosis of heart disease (0 = < 50% diameter narrowing, 1 = > 50% diameter narrowing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Labels from Features\n",
    "\n",
    "Let's now create two variables:  `y`, which is the thing we want to predict (output: `{ 0, 1 }`); and `X`, which is everything we can use to predict the specific value of `y`.\n",
    "\n",
    "With Python, splitting data out like this will not shuffle the results (something we might have to worry about if we split the data up in SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['output']\n",
    "X = df.drop('output', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training & Test Datasets\n",
    "\n",
    "The sklearn library has a method called `train_test_split` which breaks our data out into training and test datasets.  This allows us to train a model on one set of data and then see how it would perform on a completely different set of data.  This gives us a better idea of how our model might perform than simply using accuracy from the test dataset, as models tend to **overfit**:  they latch on the peculiarities of the training dataset.  If those peculiarities do not also exist in the broader population, then the trained model may come up with the wrong answer.  Having a separate test dataset that the trained model knows nothing about gives us a better idea of realistic behavior.  It also allows us to come up with a measure of how much overfitting the trained model does, as we can compare the training accuracy to the test accuracy; if there is a substantial difference between the two, our model is overfitting quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1740)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Classification\n",
    "\n",
    "We'll train the model on our training data, ignoring the test data for now.  With sklearn, this is easy:  use the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How'd we do?\n",
    "\n",
    "Let's use the `accuracy_score` method in sklearn to see just how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy score is now 83.5%, whereas for CART, it was 75.8%.  It would appear that the random forest classifier is better than the decision tree classifier when it comes to this dataset.\n",
    "\n",
    "This is fairly normal behavior--we typically see random forests beat individual decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing a sample Tree\n",
    "\n",
    "As mentioned above, the random forest classifier is really just a series of decision trees.  Let's use the `graphviz` library to visualize the first of those trees.\n",
    "\n",
    "In order to run this section, you will need the `graphviz` library.  You can get it from pip or conda:\n",
    "\n",
    "`conda install python-graphviz`\n",
    "\n",
    "`pip install graphviz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "dot_data = tree.export_graphviz(clf.estimators_[0], out_file=None, feature_names=X.columns.values.tolist(), class_names=['No heart attack', 'Heart attack'], filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaf nodes in **blue** were cases where there were heart attacks, and leaf nodes in **orange** had no heart attacks.  Non-leaf nodes are colored based on how likely they are to indicate a heart attack.\n",
    "\n",
    "As a reminder, the single decision tree from the prior notebook started with `thall <= 2.5`, so we can tell that this tree is definitely starting off differently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
