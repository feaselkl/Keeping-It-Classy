{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Passive-Aggressive Algorithms\n",
    "\n",
    "The Passive-Aggressive series of classifiers is our first example of an **online** algorithm, meaning that training is intended to happen one record at a time instead of in batches.  This works especially well in cases where you can get a quick resolution to your predictions and want to perform constant machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "clf = PassiveAggressiveClassifier(loss=\"squared_hinge\", C=1.0, max_iter=1000, random_state=0, tol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier takes a new parameter:  `tol` (tolerance).  This acts as the stopping criterion, meaning that training continues until `loss > (previous_loss - tol)`.\n",
    "\n",
    "Now let's prep the data.  Because we'll do it the same way for each, we only need to do this once.  I'll also remove the bits where we analyze the data, as we've seen it enough times already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campus_data = \"../data/CampusRecruitment.csv\"\n",
    "df = pd.read_csv(campus_data, header=0)\n",
    "y = df['status']\n",
    "X = df.drop(['sl_no', 'status', 'salary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "For this dataset, we want to use the columns leading up to `status` to determine if different college graduates were placed at a job.  Because the salary is determined by the placement status, we can't use it to predict if a new graduate will be placed, so we'll have to drop that column.  Note that if we were interested in doing a regression analysis, we could try to predict the salary given placement, but we're keeping it classy and sticking to classification algorithms only. Also, we'll drop the `sl_no` column because it's a unique student number.\n",
    "\n",
    "Unlike the heart attack dataset, this dataset includes non-numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can feed this data into the Passive-Aggressive Classifier algorithm (or pretty much any other classification algorithm), we need to convert any text data into numeric data.  There are a few common techniques for encoding.  The technique we will use for our dataset is called one-hot encoding.  What it does is \"pivot\" the categorical data, so that each distinct categorical value gets its own feature.  For example, `gender` has two values, M and F.  One-hot encoding will create new new features, one for `gender=M` and one for `gender=F`.  We need to do this for each of the non-numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# Get only categorical features\n",
    "X_object = X.select_dtypes('object')\n",
    "\n",
    "# Fit the input features to our encoder\n",
    "enc.fit(X_object)\n",
    "\n",
    "# Perform the transformation on our dataset\n",
    "codes = enc.transform(X_object).toarray()\n",
    "feature_names = enc.get_feature_names_out(['gender', 'ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'specialisation'])\n",
    "\n",
    "# Combine the new one-hot encoded features with our existing floats and everything is now numeric.\n",
    "X = pd.concat([X.select_dtypes(exclude='object'), pd.DataFrame(codes, columns=feature_names).astype(int)], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` here shows that we have the same number of rows as before (215), but the number of columns went from 12 to 21. We started with 5 floating point features. To it, we added 16 values for categorical variables: 5 of our categorical variables had 2 values, and two categorical variables had 3 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, I'm going to perform a simple label encoding of the `status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1740)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the passive-aggressive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How'd We Do?\n",
    "\n",
    "Let's first use the `accuracy_score` method in sklearn to see just how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high-line accuracy is right in line with some other algorithms, including logistic regression.  Let's compare how it does in the confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the rest of the group:\n",
    "\n",
    "|Case|kNN|XGBoost|Logistic Regression|Naive Bayes|Online PA|\n",
    "|----|---|-------|-------------------|-----------|---------|\n",
    "|True Negative|13|18|17|15|14|\n",
    "|False Positive|8|3|4|6|7|\n",
    "|False Negative|4|5|6|5|3|\n",
    "|True Positive|40|39|38|39|41|\n",
    "\n",
    "Our passive-aggressive classifier turned out to be the best at predicting placements, beating even XGBoost and Naive Bayes at the task. It did suffer a little bit with respect to non-placements, barely beating kNN and doing worse than all other algorithms.\n",
    "\n",
    "Note that, more than most other algorithms, online passive-aggressive classifiers are very dependent on the ordering of input data.  A small change could lead to a substantial accuracy difference, more so than most algorithms.  The benefits are that they tend to be very accurate (especially as information changes over time) and you do not need massive amounts of data for retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
